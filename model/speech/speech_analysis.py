import librosa
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

# 1. ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ
def load_audio(file_path):
    audio, sr = librosa.load(file_path, sr=16000)
    return audio, sr

# 2. MFCC íŠ¹ì§• ì¶”ì¶œ
def extract_mfcc(audio, sr):
    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)
    mfccs_mean = np.mean(mfccs.T, axis=0)
    return mfccs_mean

# 3. Pitch(ì–µì–‘) íŠ¹ì§• ì¶”ì¶œ
def extract_pitch(audio, sr):
    pitches, magnitudes = librosa.piptrack(y=audio, sr=sr)
    pitch_values = pitches[magnitudes > np.median(magnitudes)]
    if len(pitch_values) == 0:
        return np.array([0])
    pitch_mean = np.mean(pitch_values)
    return np.array([pitch_mean])

# 4. ì†ë„(WPM) ì¶”ì • (ì˜¤ë””ì˜¤ ê¸¸ì´ ê¸°ë°˜ ë‹¨ìˆœ ì¶”ì •)
def estimate_wpm(audio_duration_sec, estimated_word_count=150):
    """
    ì‚¬ìš©ìê°€ ì•½ estimated_word_count ë‹¨ì–´ë¥¼ ë°œí™”í–ˆë‹¤ê³  ê°€ì •í•˜ê³ ,
    WPMì„ ì¶”ì •í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.
    """
    wpm = (estimated_word_count / audio_duration_sec) * 60
    return wpm

# 5. íŠ¹ì§• ë¹„êµ (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)
def compare_features(feature1, feature2):
    similarity = cosine_similarity([feature1], [feature2])[0][0]
    return similarity

# 6. ì „ì²´ í‰ê°€
def speech_evaluate(user_audio_path):
    print("1ï¸âƒ£ ì˜¤ë””ì˜¤ ë¶ˆëŸ¬ì˜¤ê¸°")
    user_audio, sr = load_audio(user_audio_path)

    print("2ï¸âƒ£ MFCC(ë°œìŒ íŠ¹ì„±) ì¶”ì¶œ")
    user_mfcc = extract_mfcc(user_audio, sr)

    print("3ï¸âƒ£ Pitch(ì–µì–‘ íŠ¹ì„±) ì¶”ì¶œ")
    user_pitch = extract_pitch(user_audio, sr)

    print("4ï¸âƒ£ ì†ë„ ê³„ì‚° (WPM)")
    duration_sec = librosa.get_duration(filename=user_audio_path)
    user_wpm = estimate_wpm(duration_sec)

    # =========================
    # ê¸°ì¤€ê°’ (ëª¨ë¸) ì„¤ì • ë¶€ë¶„
    # =========================
    model_mfcc = np.random.normal(0, 1, 13)  # ì˜ˆì‹œ ê¸°ì¤€ MFCC (ì¶”í›„ ì‹¤ì œ ë°ì´í„°ë¡œ êµì²´)
    model_pitch = np.array([150])            # í‰ê·  pitch ê¸°ì¤€ê°’ ì˜ˆì‹œ (Hz)
    target_wpm = 140                         # ëª©í‘œ ë°œí™” ì†ë„ (WPM)
    # =========================

    print("5ï¸âƒ£ ë°œìŒ ìœ ì‚¬ë„ í‰ê°€ (MFCC)")
    mfcc_similarity = compare_features(user_mfcc, model_mfcc)
    print(f" - ë°œìŒ ìœ ì‚¬ë„ ì ìˆ˜: {mfcc_similarity:.2f}")

    print("6ï¸âƒ£ ì–µì–‘ ìœ ì‚¬ë„ í‰ê°€ (Pitch)")
    pitch_similarity = compare_features(user_pitch, model_pitch)
    print(f" - ì–µì–‘ ìœ ì‚¬ë„ ì ìˆ˜: {pitch_similarity:.2f}")

    print("7ï¸âƒ£ ì†ë„ ë¹„êµ (Words Per Minute)")
    print(f" - ì‚¬ìš©ì WPM ì¶”ì •ê°’: {user_wpm:.2f}")
    print(f" - ëª©í‘œ WPM: {target_wpm}")

    print("\n8ï¸âƒ£ ìµœì¢… í‰ê°€ ê²°ê³¼")
    if mfcc_similarity > 0.85 and pitch_similarity > 0.85 and abs(user_wpm - target_wpm) < 30:
        print("ë°œìŒ, ì–µì–‘, ì†ë„ ëª¨ë‘ ë§¤ìš° ìš°ìˆ˜í•©ë‹ˆë‹¤! ğŸ˜")
    elif mfcc_similarity > 0.7:
        print("ì¢‹ì€ ë°œí‘œì…ë‹ˆë‹¤! ì•½ê°„ ë‹¤ë“¬ìœ¼ë©´ ì™„ë²½í•´ìš”. ğŸ™‚")
    else:
        print("ì¶”ê°€ ì—°ìŠµì´ í•„ìš”í•©ë‹ˆë‹¤. ë°œìŒê³¼ ì–µì–‘ì„ ê°œì„ í•´ë´…ì‹œë‹¤. ğŸ’ª")

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    user_audio_path = "data/sample.wav"  # ìƒ˜í”Œ ìŒì„± íŒŒì¼
    speech_evaluate(user_audio_path)
